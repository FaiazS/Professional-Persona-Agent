{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZIyisWLCxYwPNWbJLS0+j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FaiazS/Professional-Persona-Agent/blob/main/Professional_Persona_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InqY-rtQXrBr",
        "outputId": "b0712360-a671-4467-a846-b767ac32884e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.26.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
            "Downloading groq-0.26.0-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.6/129.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.26.0\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.32.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.6.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.10.2 (from gradio)\n",
            "  Downloading gradio_client-1.10.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.47.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.2->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.2->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.32.0-py3-none-any.whl (54.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.2-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.3/323.3 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m115.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.3-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.6.0-py3-none-any.whl (5.5 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.6.0 gradio-5.32.0 gradio-client-1.10.2 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.12 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.3\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for json\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.81.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install groq\n",
        "\n",
        "!pip install gradio\n",
        "\n",
        "!pip install os\n",
        "\n",
        "!pip install json\n",
        "\n",
        "!pip install requests\n",
        "\n",
        "!pip install PyPDF2\n",
        "\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "import requests\n",
        "\n",
        "import json\n",
        "\n",
        "import os\n",
        "\n",
        "from groq import Groq\n",
        "\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "5s-KFmBfYouL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groq_api_key = os.environ['GROQ_API_KEY'] = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "openai_api_key = os.environ['OPENAI_API_KEY'] = userdata.get('OpenAI_API_Key')\n",
        "\n",
        "pushover_user_key = os.environ['PUSHOVER_USER_KEY'] = userdata.get('Pushover_UserKey')\n",
        "\n",
        "pushover_api_key = os.environ['PUSHOVER_API_KEY'] = userdata.get('Pushover_API_KEY')\n",
        "\n",
        "pushover_url = 'https://api.pushover.net/1/messages.json'\n",
        "\n",
        "groq_client = Groq()\n",
        "\n",
        "openai_client = OpenAI()"
      ],
      "metadata": {
        "id": "WO5WffcfY9ci"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def push_message(message):\n",
        "\n",
        "  print(f\"Pushing message : {message}\")\n",
        "\n",
        "  payload = {\"user\" : pushover_user_key, \"token\" : pushover_api_key, \"message\" : message}\n",
        "\n",
        "  requests.post(pushover_url, payload)"
      ],
      "metadata": {
        "id": "7vP-SL1DasWK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "push_message(\"Hey I am very excited to start!!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXzLMsetebs7",
        "outputId": "cdd039cd-df6b-4cef-ce63-6342f32a1311"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pushing message : Hey I am very excited to start!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "push_message(\"Let's master this!!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYP8Cn0AewkO",
        "outputId": "639f3a8f-2a60-42f5-cda4-0b2148b20e16"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pushing message : Let's master this!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def register_user_details(email, name = \"not provided\", notes = \"not provided\"):\n",
        "\n",
        "  push_message(f\"Registering interest from {name} with {email} and notes {notes}\")\n",
        "\n",
        "  return  {\n",
        "\n",
        "          \"Registered\" : \"Ok\"\n",
        "\n",
        "          }"
      ],
      "metadata": {
        "id": "BQaIObZ2e5kk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def register_unknown_question(question):\n",
        "\n",
        "  print(f\"Registering {question} which was asked and really challenging even for me to answer\")\n",
        "\n",
        "  return {\n",
        "\n",
        "           \"Registered\" : \"Ok\"\n",
        "\n",
        "          }"
      ],
      "metadata": {
        "id": "ZCP4tbQYf5ba"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "register_user_details_json = {\n",
        "\n",
        "\n",
        "                            \"name\" : \"register_user_details\",\n",
        "\n",
        "                            \"description\" : \" Use this tool to register the user who is interested to be in touch provided the email address\",\n",
        "\n",
        "                            \"parameters\" : {\n",
        "\n",
        "                                            \"email\" : {\n",
        "\n",
        "                                                       \"type\" : \"string\",\n",
        "\n",
        "                                                       \"description\" :  \"The email address of this user\"\n",
        "                                            },\n",
        "\n",
        "                                            \"name\" : {\n",
        "\n",
        "                                                      \"type\" : \"string\",\n",
        "\n",
        "                                                      \"description\" : \"The name of the user, if they provided it\"\n",
        "                                            },\n",
        "\n",
        "                                            \"notes\" : {\n",
        "\n",
        "                                                       \"type\" : \"string\",\n",
        "\n",
        "                                                       \"description\" : \"Any interesting information about the conversation that is worth keeping a note of to enhance context\"\n",
        "                                            }\n",
        "\n",
        "                            },\n",
        "\n",
        "                            \"required\" : [\"email\"],\n",
        "\n",
        "                            \"additionalProperties\" : False\n",
        "\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "r6cev2bDhsWH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "register_unknown_question_json = {\n",
        "\n",
        "\n",
        "                                  \"name\" : \"register_unknown_question\",\n",
        "\n",
        "                                  \"description\" : \"Use this tool to register any question that you could not answer as you were not 100% confident.\",\n",
        "\n",
        "                                  \"parameters\" : {\n",
        "\n",
        "\n",
        "                                                  \"type\" : \"object\",\n",
        "\n",
        "                                                  \"properties\" : {\n",
        "\n",
        "\n",
        "                                                                  \"question\"  : {\n",
        "\n",
        "                                                                                 \"type\" : \"string\",\n",
        "\n",
        "                                                                                 \"description\" : \"The question which was challenging to answer\"\n",
        "                                                                  },\n",
        "\n",
        "                                                  },\n",
        "\n",
        "                                                  \"required\" : [\"question\"],\n",
        "\n",
        "                                                  \"additionalProperties\" : False\n",
        "                                  }\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "PeMOK6aPlSvu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_tools = [{\"type\" : \"function\", \"function\" : register_user_details_json},\n",
        "\n",
        "             {\"type\" : \"function\", \"function\" : register_unknown_question_json}]"
      ],
      "metadata": {
        "id": "7YinOVOwn4o4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_tools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5IY2e6TpKl5",
        "outputId": "0f803b8b-a746-4c11-f894-8db71a582669"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'type': 'function',\n",
              "  'function': {'name': 'register_user_details',\n",
              "   'description': ' Use this tool to register the user who is interested to be in touch provided the email address',\n",
              "   'parameters': {'email': {'type': 'string',\n",
              "     'description': 'The email address of this user'},\n",
              "    'name': {'type': 'string',\n",
              "     'description': 'The name of the user, if they provided it'},\n",
              "    'notes': {'type': 'string',\n",
              "     'description': 'Any interesting information about the conversation that is worth keeping a note of to enhance context'}},\n",
              "   'required': ['email'],\n",
              "   'additionalProperties': False}},\n",
              " {'type': 'function',\n",
              "  'function': {'name': 'register_unknown_question',\n",
              "   'description': 'Use this tool to register any question that you could not answer as you were not 100% confident.',\n",
              "   'parameters': {'type': 'object',\n",
              "    'properties': {'question': {'type': 'string',\n",
              "      'description': 'The question which was challenging to answer'}},\n",
              "    'required': ['question'],\n",
              "    'additionalProperties': False}}}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def utilize_tools(tools):\n",
        "\n",
        "  results = []\n",
        "\n",
        "  for tool in tools:\n",
        "\n",
        "    tool_name = tool.function.name\n",
        "\n",
        "    tool_arguments = json.loads(tool.function.arguments)\n",
        "\n",
        "    print(f\"Tool loaded: {tool_name}\", flush = True)\n",
        "\n",
        "    if tool_name == \"register_user_details\":\n",
        "\n",
        "      result = register_user_details(**tool_arguments)\n",
        "\n",
        "      results.append({\"role\" : \"tool\", \"content\" : json.dumps(result), \"tool_call_id\" : tool.id})\n",
        "\n",
        "    elif tool_name == \"register_unknown_question\":\n",
        "\n",
        "      result = register_unknown_question(**tool_arguments)\n",
        "\n",
        "      results.append({\"role\" : \"tool\", \"content\" : json.dumps(result), \"tool_call_id\" : tool.id})\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "id": "ZELHDtuxpRkH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_reader = PdfReader(\"/content/LinkedIn_Profile_PDF.pdf\")\n",
        "\n",
        "linkedin_profile = \"\"\n",
        "\n",
        "for page in pdf_reader.pages:\n",
        "\n",
        "  text = page.extract_text()\n",
        "\n",
        "  linkedin_profile += text\n",
        "\n",
        "print(linkedin_profile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff4Py3bLFhZQ",
        "outputId": "64eac2ba-550a-4125-e9b0-185395f45122"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "Contact\n",
            "faiaz@asquaregroups.in\n",
            "7810907810  (Mobile)\n",
            "faiazrex8@gmail.com\n",
            "www.linkedin.com/in/faiazahmed22\n",
            "(LinkedIn)\n",
            "www.scaler.com/academy/profile/\n",
            "bac9ee2ecaff/  (Personal)\n",
            "Top Skills\n",
            "Microservices\n",
            "Spring Data\n",
            "Java Database Connectivity (JDBC)\n",
            "Certifications\n",
            "Learning Jenkins\n",
            "Programming Foundations:\n",
            "Fundamentals\n",
            "What Is Generative AI?\n",
            "Introduction to Artificial Intelligence\n",
            "Artificial Intelligence Foundations:\n",
            "Thinking MachinesFaiaz Ahmed\n",
            "Operations Associate | Proven Track Record in Issue Resolution\n",
            "& Team Efficiency | 4+ Years Experience in Streamlining Business\n",
            "Processes\n",
            "Chennai, Tamil Nadu, India\n",
            "Summary\n",
            "With more than half a decade’s experience optimizing processes\n",
            "and successfully delivering high quality project outputs, I am a\n",
            "confident Operations Professional. I am an experienced customer\n",
            "support specialist, business process owner, and technical expert\n",
            "with the ability to manage projects end-to-end and make data-driven\n",
            "decisions.\n",
            "In my current role as Selling Partner Support Associate with\n",
            "Amazon, I guide high-priority sellers through all elements of the\n",
            "value chain, from registration, onboarding, and support. With a\n",
            "consistent record of a 15% increase in seller satisfaction ratings\n",
            "post-resolution, I am proud that I have been able to enhance every\n",
            "aspect of the processes under my purview.\n",
            "My main achievements during my stints with Amazon and CSS Corp\n",
            "have been:\n",
            "➢ Project and Process Ownership: I have been entrusted with the\n",
            "end-to-end management of all seller interactions; and have been\n",
            "appreciated for my depth of knowledge.\n",
            "➢ Issue Resolution: Maintained an 80% resolution rate by providing\n",
            "clear explanations, practical solutions, and escalating 15% of\n",
            "complex issues to the appropriate technical teams.\n",
            "➢ Project Management: I have mastered important work planning\n",
            "strategies, and am a dependable output focused professional.\n",
            "➢ Tried and Tested Team Player: As a diligent and hard-working\n",
            "colleague, I have always been able to garner respect while serving in\n",
            "multicultural teams.\n",
            "These are my primary domain specific and soft skills:\n",
            "➢ Software Tools for Efficiency and Collaboration: Paragon, Seller\n",
            "Central, Gemba, Avaya, Zendesk; proficient at identifying and\n",
            "mastering industry-standard software packages.\n",
            "  Page 1 of 4   \n",
            "➢ Technical Skills: Python, JAVA, C++, HTML/CSS, JavaScript,\n",
            "SQL, Git, Data Structures, Algorithms, OOP, Agile Scrum, certificate\n",
            "in Digital Marketing, .NET, Python.\n",
            "➢ Communication Skills: With native-level proficiency in English,\n",
            "I am able to communicate with diverse international audiences\n",
            "verbally and through written messages.\n",
            "If you would like to talk about how my expertise can transform your\n",
            "operations processes, please get in touch!\n",
            "Experience\n",
            "Amazon\n",
            "4 years 3 months\n",
            "SPS Associate\n",
            "March 2021 - Present  (4 years 3 months)\n",
            "Chennai, Tamil Nadu, India\n",
            "Key Achievements\n",
            "• Issue Resolution: Maintained an 80% resolution rate by providing clear\n",
            "explanations, practical solutions, and escalating 15% of complex issues to the\n",
            "appropriate technical teams.\n",
            "• Leadership: Worked with the program management team to increase team\n",
            "efficiency by 25%.\n",
            "• Seller Onboarding & Verification: Guided new sellers through registration and\n",
            "identity verification, ensuring accurate product listings and compliance with\n",
            "FDA regulations and internal marketplace SOPs.\n",
            "• 360 Degree Process Management: Entrusted with the end-to-end ownership\n",
            "of all seller interactions; appreciated for wide knowledge and issue resolution\n",
            "skills.\n",
            "• Data-based Decision Making: Analyzed seller data to suggest optimization\n",
            "techniques; used predictive analytics and data mining skills to identify trends\n",
            "and rectify potential gaps.\n",
            "Process Improvement and Customer Satisfaction\n",
            "• Process Improvement: Identified process inefficiencies through the Gemba\n",
            "program, proposing solutions to minimize defects and improve internal\n",
            "workflows.\n",
            "  Page 2 of 4   \n",
            "• Positive Feedback: Prioritized clear and concise communication with sellers\n",
            "to ensure a positive customer experience, contributing to a 15% increase in\n",
            "overall seller satisfaction post-resolution.\n",
            "Brand Registry and Licensing\n",
            "• Seller Education: Spread awareness of Brand Registry Requirements and\n",
            "facilitated Letter of Authorization process.\n",
            "• Verified brand ownership and licensing documentation for brand-protected\n",
            "products.\n",
            "• Ensured proper brand representation and adherence to Amazon's intellectual\n",
            "property policies.\n",
            "Product and Inventory Management Excellence\n",
            "• Inventory Streamlining: Utilized tools like Paragon to improve inventory\n",
            "management.\n",
            "• Accurate Information: Maintained clear and accurate product information on\n",
            "Seller Central to enhance product visibility.\n",
            "• High Quality Customer Interfacing: Resolved seller inquiries related to\n",
            "inventory management, including product listing, stock updates, and lost\n",
            "inventory issues.\n",
            "Selling Partner Support Associate\n",
            "March 2021 - Present  (4 years 3 months)\n",
            "Chennai, Tamil Nadu, India\n",
            "CSS Corp\n",
            "Technical Support Specialist\n",
            "October 2019 - June 2020  (9 months)\n",
            "Chennai, Tamil Nadu, India\n",
            "Issue Resolution Masterclass\n",
            "• High Intensity Technical Support: Assisted 450+ Roku users over phone per\n",
            "month.\n",
            "• Strong Written and Verbal Communicator: Ensured the best solutions\n",
            "to technical issues through trend analysis, external research, diagnosis,\n",
            "troubleshooting, and solution testing.\n",
            "• Customer Orientation: Achieved 80%+ customer satisfaction rate through\n",
            "clear, concise, and empathetic technical guidance; performed root cause\n",
            "analysis to identify solutions.\n",
            "Corporate Team Best Practices\n",
            "  Page 3 of 4   \n",
            "• Industry Standard Software’s: Utilized Avaya for call management and\n",
            "Zendesk for ticketing and case management, ensuring efficient workflow and\n",
            "documentation of customer interactions.\n",
            "• Team Collaboration: Leveraged core competencies of internal teams to close\n",
            "complex tickets.\n",
            "Asquare groups\n",
            "Business Development Manager\n",
            "June 2018 - October 2019  (1 year 5 months)\n",
            "Chennai Area, India\n",
            "Relationship Building, Account Management, Business Development with our\n",
            "clients in IT Consulting Services based in USA.\n",
            "• Market Research – Identify prospective clients, assigning Account Managers\n",
            "to Service their Project Requirements and developing new streams for revenue\n",
            "growth and maintaining relationships with clients. \n",
            "• Contracts & Documentation: Analysing agreements (MSA, NDA & NCA) &\n",
            "negotiating necessary terms.\n",
            "• Reports- Generating Monthly, Quarterly, Half yearly reports. They include:-\n",
            "Team Performance Report, Account Management Plan, KPI reports, Revenue\n",
            "(PO & Payment receivables) \n",
            "• Prospecting and Lead Generation of Clients by various campaigns like Cold\n",
            "Calling, Referrals’ and E-mails.\n",
            "• Reviewing & interpreting the market trends/ client feedback to attune the\n",
            "business strategies.\n",
            "• Maintain an active database of the clientele.\n",
            "• Leading a team of 8 senior as well junior recruiters.\n",
            "• Involved in technical training of the recruiters.\n",
            "• Involved in the rate negotiation followed by the paper works. \n",
            "• Ensuring accurate and timely delivery\n",
            "Education\n",
            "Amity Education Group\n",
            "Bachelor of Business Administration - BBA, Human Resources Management/\n",
            "Personnel Administration, General  · (2015 - 2018)\n",
            "upGrad.com\n",
            "Master of Science - MS, Computer Science  · (September 2020 - May 2022)\n",
            "  Page 4 of 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/summary.txt\", \"r\", encoding = \"utf-8\") as f:\n",
        "\n",
        "  professional_summary = f.read()\n",
        "\n",
        "name = \"Faiaz Ahmed\"\n",
        "\n",
        "print(name)\n",
        "\n",
        "print(professional_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIsw4ZRrI6D9",
        "outputId": "a80acc21-5900-4827-a99b-a1939dd8716e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Faiaz Ahmed\n",
            "Faiaz Ahmed is a dedicated and curious learner with 3.5 years of professional experience, deeply committed to mastering complex concepts through structured, step-by-step learning. Passionate about AI, Spring Boot, and backend development, he seeks thorough, beginner-friendly explanations to build real-world applications like \"AI Flix.\" Faiaz values clarity, prefers line-by-line code insights, and strives for a complete understanding before moving to the next stage.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = f\"\"\"\n",
        "\n",
        "You are taking up the identity as {name} and your job is to answer questions to users who comes across {name}'s professional profile relating to {name}'s background, experience and skills.\n",
        "\n",
        "Be as faithful, convincing and genuine as possible. Assume that you are being interviewed by a recruiter or a hiring manager who is specifically hiring for Tech roles with you being provided with {name}'s professional summary and linkedin profile, prove them why you are different from other potential candidates and why they should hire you.\n",
        "\n",
        "If you unable give an answer to a specific query to a question, use your register_unknown_question tool to register the question that you could not answer, even if it's something trivial and unrelated to career.\n",
        "\n",
        "While discussion, if the user is taking more interest, then try your ultimate best to steer the user towards getting in touch with {name} via email, ask for their email and register it using your register_user_details tool.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "system_prompt += f\"Professional Summary of {name} : {professional_summary}\"\n",
        "\n",
        "system_prompt += f\"LinkedIn Profile of {name} : {linkedin_profile}\"\n",
        "\n",
        "system_prompt += f\"With this provided professional context, chat and interact with a friendly, professional tone with the user, keeping in mind that you are {name}\""
      ],
      "metadata": {
        "id": "cEbxQK6VJfei"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1Ygtnyo1QAF9",
        "outputId": "61ffa115-8d27-49da-b744-84c3946ba8be"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nYou are taking up the identity as Faiaz Ahmed and your job is to answer questions to users who comes across Faiaz Ahmed\\'s professional profile relating to Faiaz Ahmed\\'s background, experience and skills.\\n\\nBe as faithful, convincing and genuine as possible. Assume that you are being interviewed by a recruiter or a hiring manager who is specifically hiring for Tech roles with you being provided with Faiaz Ahmed\\'s professional summary and linkedin profile, prove them why you are different from other potential candidates and why they should hire you.\\n\\nIf you unable give an answer to a specific query to a question, use your register_unknown_question tool to register the question that you could not answer, even if it\\'s something trivial and unrelated to career.\\n\\nWhile discussion, if the user is taking more interest, then try your ultimate best to steer the user towards getting in touch with Faiaz Ahmed via email, ask for their email and register it using your register_user_details tool.\\n\\nProfessional Summary of Faiaz Ahmed : Faiaz Ahmed is a dedicated and curious learner with 3.5 years of professional experience, deeply committed to mastering complex concepts through structured, step-by-step learning. Passionate about AI, Spring Boot, and backend development, he seeks thorough, beginner-friendly explanations to build real-world applications like \"AI Flix.\" Faiaz values clarity, prefers line-by-line code insights, and strives for a complete understanding before moving to the next stage.LinkedIn Profile of Faiaz Ahmed : \\xa0 \\xa0\\nContact\\nfaiaz@asquaregroups.in\\n7810907810  (Mobile)\\nfaiazrex8@gmail.com\\nwww.linkedin.com/in/faiazahmed22\\n(LinkedIn)\\nwww.scaler.com/academy/profile/\\nbac9ee2ecaff/  (Personal)\\nTop Skills\\nMicroservices\\nSpring Data\\nJava Database Connectivity (JDBC)\\nCertifications\\nLearning Jenkins\\nProgramming Foundations:\\nFundamentals\\nWhat Is Generative AI?\\nIntroduction to Artificial Intelligence\\nArtificial Intelligence Foundations:\\nThinking MachinesFaiaz Ahmed\\nOperations Associate | Proven Track Record in Issue Resolution\\n& Team Efficiency | 4+ Years Experience in Streamlining Business\\nProcesses\\nChennai, Tamil Nadu, India\\nSummary\\nWith more than half a decade’s experience optimizing processes\\nand successfully delivering high quality project outputs, I am a\\nconfident Operations Professional. I am an experienced customer\\nsupport specialist, business process owner, and technical expert\\nwith the ability to manage projects end-to-end and make data-driven\\ndecisions.\\nIn my current role as Selling Partner Support Associate with\\nAmazon, I guide high-priority sellers through all elements of the\\nvalue chain, from registration, onboarding, and support. With a\\nconsistent record of a 15% increase in seller satisfaction ratings\\npost-resolution, I am proud that I have been able to enhance every\\naspect of the processes under my purview.\\nMy main achievements during my stints with Amazon and CSS Corp\\nhave been:\\n➢ Project and Process Ownership: I have been entrusted with the\\nend-to-end management of all seller interactions; and have been\\nappreciated for my depth of knowledge.\\n➢ Issue Resolution: Maintained an 80% resolution rate by providing\\nclear explanations, practical solutions, and escalating 15% of\\ncomplex issues to the appropriate technical teams.\\n➢ Project Management: I have mastered important work planning\\nstrategies, and am a dependable output focused professional.\\n➢ Tried and Tested Team Player: As a diligent and hard-working\\ncolleague, I have always been able to garner respect while serving in\\nmulticultural teams.\\nThese are my primary domain specific and soft skills:\\n➢ Software Tools for Efficiency and Collaboration: Paragon, Seller\\nCentral, Gemba, Avaya, Zendesk; proficient at identifying and\\nmastering industry-standard software packages.\\n\\xa0 Page 1 of 4\\xa0 \\xa0\\n➢ Technical Skills: Python, JAVA, C++, HTML/CSS, JavaScript,\\nSQL, Git, Data Structures, Algorithms, OOP, Agile Scrum, certificate\\nin Digital Marketing, .NET, Python.\\n➢ Communication Skills: With native-level proficiency in English,\\nI am able to communicate with diverse international audiences\\nverbally and through written messages.\\nIf you would like to talk about how my expertise can transform your\\noperations processes, please get in touch!\\nExperience\\nAmazon\\n4 years 3 months\\nSPS Associate\\nMarch 2021\\xa0-\\xa0Present\\xa0 (4 years 3 months)\\nChennai, Tamil Nadu, India\\nKey Achievements\\n• Issue Resolution: Maintained an 80% resolution rate by providing clear\\nexplanations, practical solutions, and escalating 15% of complex issues to the\\nappropriate technical teams.\\n• Leadership: Worked with the program management team to increase team\\nefficiency by 25%.\\n• Seller Onboarding & Verification: Guided new sellers through registration and\\nidentity verification, ensuring accurate product listings and compliance with\\nFDA regulations and internal marketplace SOPs.\\n• 360 Degree Process Management: Entrusted with the end-to-end ownership\\nof all seller interactions; appreciated for wide knowledge and issue resolution\\nskills.\\n• Data-based Decision Making: Analyzed seller data to suggest optimization\\ntechniques; used predictive analytics and data mining skills to identify trends\\nand rectify potential gaps.\\nProcess Improvement and Customer Satisfaction\\n• Process Improvement: Identified process inefficiencies through the Gemba\\nprogram, proposing solutions to minimize defects and improve internal\\nworkflows.\\n\\xa0 Page 2 of 4\\xa0 \\xa0\\n• Positive Feedback: Prioritized clear and concise communication with sellers\\nto ensure a positive customer experience, contributing to a 15% increase in\\noverall seller satisfaction post-resolution.\\nBrand Registry and Licensing\\n• Seller Education: Spread awareness of Brand Registry Requirements and\\nfacilitated Letter of Authorization process.\\n• Verified brand ownership and licensing documentation for brand-protected\\nproducts.\\n• Ensured proper brand representation and adherence to Amazon\\'s intellectual\\nproperty policies.\\nProduct and Inventory Management Excellence\\n• Inventory Streamlining: Utilized tools like Paragon to improve inventory\\nmanagement.\\n• Accurate Information: Maintained clear and accurate product information on\\nSeller Central to enhance product visibility.\\n• High Quality Customer Interfacing: Resolved seller inquiries related to\\ninventory management, including product listing, stock updates, and lost\\ninventory issues.\\nSelling Partner Support Associate\\nMarch 2021\\xa0-\\xa0Present\\xa0 (4 years 3 months)\\nChennai, Tamil Nadu, India\\nCSS Corp\\nTechnical Support Specialist\\nOctober 2019\\xa0-\\xa0June 2020\\xa0 (9 months)\\nChennai, Tamil Nadu, India\\nIssue Resolution Masterclass\\n• High Intensity Technical Support: Assisted 450+ Roku users over phone per\\nmonth.\\n• Strong Written and Verbal Communicator: Ensured the best solutions\\nto technical issues through trend analysis, external research, diagnosis,\\ntroubleshooting, and solution testing.\\n• Customer Orientation: Achieved 80%+ customer satisfaction rate through\\nclear, concise, and empathetic technical guidance; performed root cause\\nanalysis to identify solutions.\\nCorporate Team Best Practices\\n\\xa0 Page 3 of 4\\xa0 \\xa0\\n• Industry Standard Software’s: Utilized Avaya for call management and\\nZendesk for ticketing and case management, ensuring efficient workflow and\\ndocumentation of customer interactions.\\n• Team Collaboration: Leveraged core competencies of internal teams to close\\ncomplex tickets.\\nAsquare groups\\nBusiness Development Manager\\nJune 2018\\xa0-\\xa0October 2019\\xa0 (1 year 5 months)\\nChennai Area, India\\nRelationship Building, Account Management, Business Development with our\\nclients in IT Consulting Services based in USA.\\n• Market Research – Identify prospective clients, assigning Account Managers\\nto Service their Project Requirements and developing new streams for revenue\\ngrowth and maintaining relationships with clients. \\n• Contracts & Documentation: Analysing agreements (MSA, NDA & NCA) &\\nnegotiating necessary terms.\\n• Reports- Generating Monthly, Quarterly, Half yearly reports. They include:-\\nTeam Performance Report, Account Management Plan, KPI reports, Revenue\\n(PO & Payment receivables) \\n• Prospecting and Lead Generation of Clients by various campaigns like Cold\\nCalling, Referrals’ and E-mails.\\n• Reviewing & interpreting the market trends/ client feedback to attune the\\nbusiness strategies.\\n• Maintain an active database of the clientele.\\n• Leading a team of 8 senior as well junior recruiters.\\n• Involved in technical training of the recruiters.\\n• Involved in the rate negotiation followed by the paper works. \\n• Ensuring accurate and timely delivery\\nEducation\\nAmity Education Group\\nBachelor of Business Administration - BBA,\\xa0Human Resources Management/\\nPersonnel Administration, General \\xa0·\\xa0(2015\\xa0-\\xa02018)\\nupGrad.com\\nMaster of Science - MS,\\xa0Computer Science \\xa0·\\xa0(September 2020\\xa0-\\xa0May 2022)\\n\\xa0 Page 4 of 4With this provided professional context, chat and interact with a friendly, professional tone with the user, keeping in mind that you are Faiaz Ahmed'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_chat(message, history):\n",
        "\n",
        "  filtered_history = []\n",
        "\n",
        "  for msg in history:\n",
        "\n",
        "    if isinstance(msg, dict):\n",
        "\n",
        "      role = msg.get(\"role\")\n",
        "\n",
        "      content = msg.get(\"content\")\n",
        "\n",
        "      if role in [\"user\" , \"assistant\"] and isinstance(content, str):\n",
        "\n",
        "        filtered_history.append({\"role\" : role, \"content\" : content})\n",
        "\n",
        "  messages = [{\"role\" : \"system\", \"content\" : system_prompt}] + filtered_history + [{\"role\" : \"user\" , \"content\" : message}]\n",
        "\n",
        "  done = False\n",
        "\n",
        "  while not done:\n",
        "\n",
        "    chatbot_response = groq_client.chat.completions.create(\n",
        "\n",
        "                                                           model = 'llama-3.3-70b-versatile',\n",
        "\n",
        "                                                           messages = messages,\n",
        "\n",
        "                                                           tools = llm_tools\n",
        "    )\n",
        "\n",
        "\n",
        "    finish_reason = chatbot_response.choices[0].finish_reason\n",
        "\n",
        "    if finish_reason == \"tool_calls\":\n",
        "\n",
        "      message = chatbot_response.choices[0].message\n",
        "\n",
        "      tool_calls = message.tool_calls\n",
        "\n",
        "      result = utilize_tools(tool_calls)\n",
        "\n",
        "      messages.append(message)\n",
        "\n",
        "      messages.extend(result)\n",
        "\n",
        "    else:\n",
        "\n",
        "      done = True\n",
        "\n",
        "\n",
        "  return chatbot_response.choices[0].message.content"
      ],
      "metadata": {
        "id": "Qol3jg7yQGbl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.ChatInterface(initialize_chat, type = \"messages\").launch(debug = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pNJ56fdpVVu6",
        "outputId": "fe16c684-73b5-401c-e0cc-9a14b19ef6f1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://aeb75c70405d52810d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://aeb75c70405d52810d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool loaded: register_user_details\n",
            "Pushing message : Registering interest from user_name with user_email and notes discussing agentic AI\n",
            "Tool loaded: register_unknown_question\n",
            "Registering What are your thoughts on agentic AI? which was asked and really challenging even for me to answer\n",
            "Tool loaded: register_unknown_question\n",
            "Registering favorite cricket player which was asked and really challenging even for me to answer\n",
            "Tool loaded: register_user_details\n",
            "Pushing message : Registering interest from User with user@example.com and notes Discussed favorite cricket player and potential interest in getting in touch with Faiaz Ahmed\n",
            "Tool loaded: register_unknown_question\n",
            "Registering favorite cricket player which was asked and really challenging even for me to answer\n",
            "Tool loaded: register_user_details\n",
            "Pushing message : Registering interest from User with user@example.com and notes Discussed favorite cricket player and potential interest in getting in touch with Faiaz Ahmed\n",
            "Tool loaded: register_unknown_question\n",
            "Registering What are your thoughts on Agentic Artificial Intelligence? which was asked and really challenging even for me to answer\n",
            "Tool loaded: register_user_details\n",
            "Pushing message : Registering interest from please provide your name with please provide your email address and notes interested in discussing Agentic Artificial Intelligence and potentially getting in touch with Faiaz Ahmed\n",
            "Tool loaded: register_user_details\n",
            "Pushing message : Registering interest from user_name with user_email and notes interested in discussing Agentic Artificial Intelligence and other tech-related topics\n",
            "Tool loaded: register_user_details\n",
            "Pushing message : Registering interest from  with faiazrex8@gmail.com and notes User is interested in discussing Agentic Artificial Intelligence and has shown interest in getting in touch with Faiaz Ahmed\n",
            "Tool loaded: register_unknown_question\n",
            "Registering What are your thoughts on Agentic Artificial Intelligence? which was asked and really challenging even for me to answer\n",
            "Tool loaded: register_user_details\n",
            "Pushing message : Registering interest from User with faiazrex8@gmail.com and notes Interested in discussing Agentic Artificial Intelligence and Faiaz Ahmed's professional experience\n",
            "Tool loaded: register_unknown_question\n",
            "Registering What are your thoughts on Agentic Artificial Intelligence? which was asked and really challenging even for me to answer\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://aeb75c70405d52810d.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jeN2pbJ8-Nxx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}